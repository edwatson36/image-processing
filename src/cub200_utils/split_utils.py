# -*- coding: utf-8 -*-
"""split_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZwK4Pb0Nwnqr9ronPLH3ILzzptFzkMMC
"""

from pathlib import Path
import plotly.express as px
import pandas as pd
from sklearn.model_selection import train_test_split
from typing import List, Dict, Tuple
from io_utils import merge_metadata
from constants import SPLIT_FLAG, TRAIN_VALUE, TEST_VALUE, CLASS_FLAG, IMAGE_ID

# Perform split - calls merge_data() and then creates the splits
def create_test_split(dataset_dir: Path) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    Create the official train/test split for the CUB-200-2011 dataset.

    This function loads the merged metadata and partitions it into
    training and test DataFrames based on the dataset-defined split flag.

    Args:
        dataset_dir (Path): Root directory of the extracted CUB-200-2011 dataset.

    Returns:
        tuple[pd.DataFrame, pd.DataFrame]:
            (train_df, test_df), two DataFrames containing image-level
            metadata and labels corresponding to the official training
            and test splits. Column definitions are determined by merge_metadata().
    """
    # Create merged df
    merged_df = merge_metadata(dataset_dir)

    # Create train-test split
    train_df = merged_df[merged_df[SPLIT_FLAG] == TRAIN_VALUE].reset_index(drop=True)
    test_df = merged_df[merged_df[SPLIT_FLAG] == TEST_VALUE].reset_index(drop=True)

    print(f"Total images: {len(merged_df)}")
    print(f"Train: {len(train_df)} | Test: {len(test_df)} | Train_Classes: {train_df['class_id'].nunique()}| Test_Classes: {test_df['class_id'].nunique()}")
    return train_df, test_df


# Create validation split - input train images only
def create_validation_split(
    train_df: pd.DataFrame,
    val_fraction: float = 0.2,
    random_state: int = 42,
    stratify: bool = True
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Split the official training set into training and validation subsets.

    Args:
        train_df (pd.DataFrame): training DataFrame (from create_test_split()).
        val_fraction (float): Fraction of training data to use for validation (default=0.2).
        random_state (int): Random seed for reproducibility.
        stratify (bool): Preserve class distribution if True (default=True).

    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: (train_sub_df, val_sub_df)
    """
    stratify_labels = train_df[CLASS_FLAG] if stratify else None

    train_sub_df, val_sub_df = train_test_split(
        train_df,
        test_size=val_fraction,
        random_state=random_state,
        stratify=stratify_labels
    )

    train_sub_df = train_sub_df.reset_index(drop=True)
    val_sub_df = val_sub_df.reset_index(drop=True)

    print(f"Training subset: {len(train_sub_df)} images, "
          f"{train_sub_df['class_id'].nunique()} classes")
    print(f"Validation subset: {len(val_sub_df)} images, "
          f"{val_sub_df['class_id'].nunique()} classes")

    return train_sub_df, val_sub_df


# Define function to check that there are no overlapping images between train, validation, and test sets
def check_no_overlap(train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame) -> None:
    """
    Checks that there are no overlapping images between train, validation, and test sets using set operator &
    """
    train_ids = set(train_df[IMAGE_ID])
    val_ids = set(val_df[IMAGE_ID])
    test_ids = set(test_df[IMAGE_ID])

    # Compute intersections between sets with &
    overlap_train_val = train_ids & val_ids
    overlap_train_test = train_ids & test_ids
    overlap_val_test = val_ids & test_ids

    assert not overlap_train_val, f"Overlap between train and val: {overlap_train_val}"
    assert not overlap_train_test, f"Overlap between train and test: {overlap_train_test}"
    assert not overlap_val_test, f"Overlap between val and test: {overlap_val_test}"

    print("No overlapping image_ids between train, validation, and test sets.")


# Define function to plot class balance
def plot_class_balance(dfs: dict[str, pd.DataFrame]) -> None:
    """
    Plot cumulative class distribution for each given dataset split.

    Args:
        dfs (dict[str, pd.DataFrame]): Dictionary of DataFrames, e.g.
            {"train": train_df, "val": val_df, "test": test_df}
    Returns:
        None
    """
    plot_data = []

    for name, df in dfs.items():
        # Count images per class
        class_counts = (
            df[CLASS_FLAG]
            .value_counts()
            .sort_values()
            .reset_index()
        )

        # Compute cumulative percentage
        class_counts["cum_percent"] = (class_counts["count"].cumsum() / class_counts["count"].sum()) * 100
        class_counts["rank"] = range(1, len(class_counts) + 1)
        class_counts["dataset"] = name

        plot_data.append(class_counts)

    combined_df = pd.concat(plot_data, ignore_index=True)

    # Plot cumulative distribution
    fig = px.line(
        combined_df,
        x="rank",
        y="cum_percent",
        color="dataset",
        markers=True,
        title="Cumulative Class Distribution Across Splits",
        labels={
            "rank": "Class Rank (sorted by frequency)",
            "cum_percent": "Cumulative % of Images",
            "dataset": "Dataset Split"
        }
    )

    max_classes = max(df[CLASS_FLAG].nunique() for df in dfs.values())

    fig.update_layout(
        yaxis=dict(range=[0, 100]),
        xaxis=dict(title=f"Class Rank (1-{max_classes})"),
        template="plotly_white",
        legend=dict(title="Split", orientation="h", y=-0.25, x=0.3)
    )

    fig.show()